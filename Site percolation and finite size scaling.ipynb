{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dominant-terminal",
   "metadata": {
    "id": "nlPPy04td7LK"
   },
   "source": [
    "# Site percolation using tree-based union/find algorithm and finite size scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerical-powell",
   "metadata": {
    "id": "d6WETlXFd7LP"
   },
   "source": [
    "## Library and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "classical-employer",
   "metadata": {
    "id": "WFGgXVh6d7LQ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "varying-nursery",
   "metadata": {
    "id": "VdKUTQCed7LR"
   },
   "outputs": [],
   "source": [
    "def num_of_zero_in_list(lists):\n",
    "    '''\n",
    "    Count number of 0 in a list.\n",
    "    '''\n",
    "    x = 0\n",
    "    for component in lists:\n",
    "        if component == 0:\n",
    "            x += 1\n",
    "    return x\n",
    "\n",
    "def num_in_dict(dictionary, number):\n",
    "    '''\n",
    "    Count number of components in a dictionary which is included key value of \"number\".\n",
    "    '''\n",
    "    a_list = dictionary[number]\n",
    "    L = len(a_list)\n",
    "    return L\n",
    "\n",
    "def dict_to_matrix(lattice_size, dictionary):\n",
    "    '''\n",
    "    Convert label_dictionary into matrix.\n",
    "    '''\n",
    "    matrix = np.zeros((lattice_size, lattice_size))\n",
    "    for label in dictionary:\n",
    "        if label != 0:\n",
    "            lits = dictionary[label]\n",
    "            for coordi in lits:\n",
    "                x, y = coordi[0], coordi[1] \n",
    "                matrix[x,y] = label\n",
    "        else:\n",
    "            continue\n",
    "    matrix = matrix\n",
    "    return matrix\n",
    "\n",
    "def near_by_sites(lists):\n",
    "    '''\n",
    "    Find occupied neighbors.\n",
    "    '''\n",
    "    x = []\n",
    "    for component in lists:\n",
    "        if component != 0:\n",
    "            x.append(component)\n",
    "    return x\n",
    "\n",
    "def multi(lists):\n",
    "    '''\n",
    "    Calculate multiplicities in a list.\n",
    "    '''\n",
    "    mul = []\n",
    "    for component in lists:\n",
    "        if lists.count(component) == 1:\n",
    "            mul.append(1)\n",
    "        elif lists.count(component) == 2:\n",
    "            mul.append(2)\n",
    "        elif lists.count(component) == 3:\n",
    "            mul.append(3)\n",
    "        elif lists.count(component) == 4:\n",
    "            mul.append(4)\n",
    "    return mul\n",
    "\n",
    "def add_a_site(configuration):\n",
    "    '''\n",
    "    Add a randomly chosen site in a square lattice.\n",
    "    '''\n",
    "    L = len(configuration)\n",
    "    lin_con = configuration.reshape(L**2)\n",
    "    while True:\n",
    "        c = np.random.randint(0,L**2)\n",
    "        if lin_con[c] == 0:\n",
    "            lin_con[c]= 2\n",
    "            break\n",
    "    configuration = lin_con.reshape((L,L))\n",
    "    return configuration\n",
    "\n",
    "def number_of_cluster(dictionary):\n",
    "    '''\n",
    "    Compute number of cluster in a given configuration.\n",
    "    '''\n",
    "    number_of_clust = 0\n",
    "    for key in dictionary:\n",
    "        number_of_clust += 1\n",
    "    return number_of_clust\n",
    "\n",
    "def giant_cluster_size(dictionary):\n",
    "    '''\n",
    "    Calculate the size of giant cluster in a given configuration.\n",
    "    '''\n",
    "    size_of_clusters = []\n",
    "    for key in dictionary:\n",
    "        size_of_clusters.append(len(dictionary[key]))\n",
    "    m = max(size_of_clusters)\n",
    "    return m\n",
    "\n",
    "def cluster_sizes(dictionary):\n",
    "    '''\n",
    "    To calculate susceptibility in percolation, we should compute mean cluster size of \n",
    "    the configuration except for the largest cluster. \n",
    "    '''\n",
    "    number_of_clusters = len(dictionary)\n",
    "    what_sizes = []\n",
    "    for key in dictionary:\n",
    "        what_sizes.append(len(dictionary[key])) # a list contains size of each cluster\n",
    "        \n",
    "    maximum_cluster_size = max(what_sizes) #the largest cluster must be omitted from the summation\n",
    "    what_sizes.remove(maximum_cluster_size)\n",
    "    what_sizes = (np.array(what_sizes))**2\n",
    "    Size = np.sum(what_sizes)\n",
    "    \n",
    "    return Size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transparent-directory",
   "metadata": {
    "id": "zIu4BdaJd7LS"
   },
   "source": [
    "### Union/find algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "historic-sword",
   "metadata": {
    "id": "M3YuOXKCd7LT"
   },
   "outputs": [],
   "source": [
    "def union_find(lattice_size, number_of_occupied_sites):\n",
    "    '''\n",
    "    Tree-based union/find algorithm which is more efficient than conventional algorithms.\n",
    "    This code also contain calculation of giant cluster size and average cluster size of the input configuration.\n",
    "    Some part doesn't include optimization for faster code run. If you need to make a configuration faster, use # code.\n",
    "    '''\n",
    "    L = lattice_size\n",
    "    configuration, label_matrix = np.zeros((L,L)), np.zeros((L,L))\n",
    "    label = 0\n",
    "    label_dict = {} #an empty dictionary\n",
    "    gc_ratio = []\n",
    "    mean_cluster = []\n",
    "    \n",
    "    \n",
    "    for n in range(number_of_occupied_sites):\n",
    "        if n == 0:\n",
    "            gc_ratio.append(0)\n",
    "            mean_cluster.append(0)\n",
    "\n",
    "        elif n > 0:\n",
    "            add_a_site(configuration)\n",
    "\n",
    "            for i in range(L):\n",
    "                for j in range(L):\n",
    "                    if configuration[i,j] == 2:\n",
    "                        lmleft, lmright, lmabove, lmbelow = label_matrix[i,(j-1)%L], label_matrix[i,(j+1)%L], label_matrix[(i-1)%L,j], label_matrix[(i+1)%L,j]\n",
    "                        lmarr = [lmleft, lmright, lmabove, lmbelow]\n",
    "                        value = num_of_zero_in_list(lmarr)\n",
    "                        numbers = []\n",
    "                        sites = []\n",
    "\n",
    "                        if value == 4: #Zero neighbor\n",
    "                            label += 1\n",
    "                            label_dict[label] = [(i,j)] #make new key and contain it's coordinate there.\n",
    "\n",
    "                        elif value == 3: #One neighbor\n",
    "                            for k in lmarr:\n",
    "                                if k != 0: #one neighbor is occupied\n",
    "                                    label_dict[k] += [(i,j)] #append a coordinate\n",
    "\n",
    "                        elif value == 2: #Two neighbors\n",
    "                            sites = near_by_sites(lmarr)\n",
    "                            if sites[0] != sites[1]: #labels are different\n",
    "                                label_dict[sites[0]] += [(i,j)] + label_dict[sites[1]]\n",
    "                                label_dict.pop(sites[1])\n",
    "                                #for k in sites: #with respect to occupied sites,\n",
    "                                #    numbers.append(num_in_dict(label_dict, k))\n",
    "                                #if numbers[0] > numbers[1]:\n",
    "                                #    label_dict[sites[0]] += [(i,j)] + label_dict[sites[1]]\n",
    "                                #    label_dict.pop(sites[1])\n",
    "                                #else:\n",
    "                                #    label_dict[sites[1]] += [(i,j)] + label_dict[sites[0]] \n",
    "                                #    label_dict.pop(sites[0])\n",
    "                            elif sites[0] == sites[1]: #label of two sites are equal.\n",
    "                                label_dict[sites[0]] += [(i,j)]\n",
    "\n",
    "                        elif value == 1: #if three neighbors are preoccupied.\n",
    "                            sites = near_by_sites(lmarr)\n",
    "                            multiplicity = multi(sites)\n",
    "                            if 3 in multiplicity: #multiplicity = [3,3,3]\n",
    "                                label_dict[sites[0]] += [(i,j)]\n",
    "                            elif 1 and 2 in multiplicity: #multiplicity = [1,2,2]\n",
    "                                N = list(set(sites))\n",
    "                                label_dict[N[0]] += [(i,j)] + label_dict[N[1]]\n",
    "                                label_dict.pop(N[1])\n",
    "                                #if num_in_dict(label_dict, N[0]) > num_in_dict(label_dict, N[1]):\n",
    "                                #    label_dict[N[0]] += [(i,j)] + label_dict[N[1]]\n",
    "                                #    label_dict.pop(N[1])\n",
    "                                #else:\n",
    "                                #    label_dict[N[1]] += [(i,j)] + label_dict[N[0]]\n",
    "                                #    label_dict.pop(N[0])                            \n",
    "                            elif 1 in multiplicity and 2 not in multiplicity: #3개 모두 다른 label multiplicity = [1,1,1]\n",
    "                                for q in range(len(sites)):\n",
    "                                    numbers.append((num_in_dict(label_dict, sites[q]), q))\n",
    "                                numbers.sort() \n",
    "                                label_dict[sites[numbers[2][1]]] += [(i,j)] + label_dict[sites[numbers[0][1]]] + label_dict[sites[numbers[1][1]]]\n",
    "                                label_dict.pop(sites[numbers[0][1]])\n",
    "                                label_dict.pop(sites[numbers[1][1]])\n",
    "\n",
    "                        elif value == 0: #all neighbor sites is occupied.\n",
    "                            multiplicity = multi(lmarr)\n",
    "                            N = list(set(lmarr))\n",
    "                            if 4 in multiplicity: #multiplicity = [4,4,4,4]\n",
    "                                label_dict[lmleft] += [(i,j)]\n",
    "                            elif 1 and 3 in multiplicity: #multiplicity = [1,3,3,3]\n",
    "                                label_dict[N[0]] += [(i,j)] + label_dict[N[1]]\n",
    "                                label_dict.pop(N[1])\n",
    "                                #if num_in_dict(label_dict, N[0]) > num_in_dict(label_dict, N[1]):\n",
    "                                #    label_dict[N[0]] += [(i,j)] + label_dict[N[1]]\n",
    "                                #    label_dict.pop(N[1])\n",
    "                                #else:\n",
    "                                #    label_dict[N[1]] += [(i,j)] + label_dict[N[0]]\n",
    "                                #    label_dict.pop(N[0])   \n",
    "                            elif 2 in multiplicity and 1 not in multiplicity: #multiplicity = [2,2, 2,2]\n",
    "                                label_dict[N[0]] += [(i,j)] + label_dict[N[1]]\n",
    "                                label_dict.pop(N[1])\n",
    "\n",
    "                                #if num_in_dict(label_dict, N[0]) > num_in_dict(label_dict, N[1]):\n",
    "                                #    label_dict[N[0]] += [(i,j)] + label_dict[N[1]]\n",
    "                                #    label_dict.pop(N[1])\n",
    "                                #else:\n",
    "                                #    label_dict[N[1]] += [(i,j)] + label_dict[N[0]]\n",
    "                                #    label_dict.pop(N[0])\n",
    "                            elif 1 and 2 in multiplicity and 3 not in multiplicity: #multiplicity = [1,1,2,2]\n",
    "                                for l in range(len(N)):\n",
    "                                    numbers.append((num_in_dict(label_dict, N[l]), l))\n",
    "                                numbers.sort()\n",
    "                                label_dict[N[numbers[2][1]]] += [(i,j)] + label_dict[N[numbers[0][1]]] + label_dict[N[numbers[1][1]]]\n",
    "                                label_dict.pop(N[numbers[0][1]])\n",
    "                                label_dict.pop(N[numbers[1][1]])     \n",
    "                            elif 1 in multiplicity and 2 not in multiplicity and 3 not in multiplicity: #multiplicity = [1,1,1,1]\n",
    "                                for m in range(len(lmarr)):\n",
    "                                    numbers.append((num_in_dict(label_dict, lmarr[m]), m))\n",
    "                                numbers.sort()\n",
    "                                label_dict[lmarr[numbers[3][1]]] += [(i,j)] + label_dict[lmarr[numbers[0][1]]] + label_dict[lmarr[numbers[1][1]]] + label_dict[lmarr[numbers[2][1]]]\n",
    "                                label_dict.pop(lmarr[numbers[0][1]])\n",
    "                                label_dict.pop(lmarr[numbers[1][1]])    \n",
    "                                label_dict.pop(lmarr[numbers[2][1]])    \n",
    "\n",
    "                        configuration[i,j] = 1\n",
    "                        label_matrix = dict_to_matrix(L, label_dict)\n",
    "                        gc_ratio.append(giant_cluster_size(label_dict)/(L**2))\n",
    "                        mean_cluster.append(cluster_sizes(label_dict)/(L**2))\n",
    "                        break\n",
    "                else:\n",
    "                    continue\n",
    "                break \n",
    "    return configuration, label_matrix, gc_ratio, mean_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "subjective-herald",
   "metadata": {
    "id": "VpSXzOm4d7La"
   },
   "outputs": [],
   "source": [
    "def ensemble_union_find(lattice_size, number_of_ensemble):\n",
    "    '''\n",
    "    By computing percolation with number_of_ensemble times, return ensemble averaged values.\n",
    "    '''\n",
    "    alls = []\n",
    "    sus_alls = []\n",
    "    for n in range(number_of_ensemble):\n",
    "        m, lab, gc, mc = union_find(lattice_size, lattice_size**2)\n",
    "        alls.append(np.array(gc))\n",
    "        sus_alls.append(np.array(mc))\n",
    "    # Z는 average magnetization\n",
    "    Z = np.zeros(len(gc))\n",
    "    Z2 = np.zeros(len(gc))\n",
    "    Z4 = np.zeros(len(gc))\n",
    "    SS = np.zeros(len(mc))\n",
    "    \n",
    "    for i in range(number_of_ensemble):\n",
    "        Z += alls[i]\n",
    "        Z2 += (alls[i])**2\n",
    "        Z4 += (alls[i])**4\n",
    "        SS += sus_alls[i]\n",
    "        \n",
    "    average = Z / number_of_ensemble\n",
    "    suscept = SS / number_of_ensemble\n",
    "    cumulant = np.ones(len(gc)) - (Z4/number_of_ensemble) / (3*(Z2/number_of_ensemble)**2) \n",
    "    \n",
    "    return average, suscept, cumulant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-template",
   "metadata": {
    "id": "zvBGzD14d7Lk"
   },
   "source": [
    "## Finite size scaling\n",
    "Set $x$ axis as $(p-p_c)L^{1/\\nu}$ and  $y$ axis as $S_{\\infty}L^{\\beta/\\nu}$ for fraction of giant cluster. ($S_{\\infty}$ is fraction of giant cluster at infinite lattice.)<br>\n",
    "Set $x$ axis as $(p-p_c)L^{1/\\nu}$ and $y$ axis as $\\chi L^{\\gamma/\\nu}$ for its susceptibility. <br>\n",
    "$\\beta = 5/36$, $\\nu = 4/3$, and $\\gamma = 43/18$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "civil-baseline",
   "metadata": {
    "id": "EMkDAwDAd7Ll"
   },
   "outputs": [],
   "source": [
    "pc = 0.595 #percolation threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "caroline-turtle",
   "metadata": {
    "id": "GZZW-bjNd7Ll"
   },
   "outputs": [],
   "source": [
    "def percolation_finte_size_scaling(linear_lattice_size, average_fraction, susceptibility, percolation_threshold):\n",
    "    x = np.arange(0,linear_lattice_size**2)/(linear_lattice_size**2)\n",
    "    x_pc = x - percolation_threshold\n",
    "    X = x_pc * linear_lattice_size**(3/4)\n",
    "    \n",
    "    scaled_Af = average_fraction * linear_lattice_size**(5/36 * 3/4)\n",
    "    scaled_Sus = susceptibility * linear_lattice_size**(-43/18 * 3/4)\n",
    "    \n",
    "    return X, scaled_Af, scaled_Sus"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "PC_finite.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
